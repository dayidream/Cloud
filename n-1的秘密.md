# n-1的秘密



## 边际分布与联合分布

边际分布和联合分布是概率论中描述随机变量分布的两个重要概念。

1. **联合分布（Joint Distribution）**：
   - 定义：当我们考虑两个（或更多）随机变量同时发生的概率分布时，就是在谈论它们的联合分布。
   - 例如：假设有两个随机变量 X 和 Y，X 可能代表一个人的年龄，而 Y 代表其收入。X 和 Y 的联合分布会告诉我们在特定年龄和收入组合下的概率。
   - 表示：联合分布可以通过联合概率密度函数（对于连续随机变量）或联合概率质量函数（对于离散随机变量）来表示。

2. **边际分布（Marginal Distribution）**：
   - 定义：边际分布描述的是单个随机变量的概率分布，而不考虑其他变量。
   - 例如：在上述的年龄和收入的例子中，年龄 X 的边际分布只关注年龄的概率分布，不考虑收入 Y；同理，收入 Y 的边际分布只关注收入的概率分布，不考虑年龄 X。
   - 计算：边际分布可以通过对其他变量的联合分布进行求和（离散情况）或积分（连续情况）来获得。

边际分布和联合分布之间的关系是：边际分布可以从联合分布中得出，但联合分布包含的信息更多，它描述了变量间的关系，而边际分布则忽略了这种关系。在统计学和概率论中，理解这两种分布及它们之间的关系对于分析多变量数据是非常重要的。

### 例子

让我们通过一个简单的例子来理解联合分布和边际分布。

假设我们有一个小型公司，它只有两个员工，Alice 和 Bob。我们关注的随机变量是每个员工每天完成的任务数量。为简化，假设每个员工每天只能完成0个、1个或2个任务。

首先，我们列出他们每天完成任务数量的所有可能组合，以及这些组合发生的概率。这就是联合分布。

| Alice\Bob | 0    | 1    | 2    |
| --------- | ---- | ---- | ---- |
| **0**     | 0.05 | 0.10 | 0.05 |
| **1**     | 0.10 | 0.20 | 0.10 |
| **2**     | 0.05 | 0.10 | 0.25 |

在这个表格中，行表示 Alice 完成的任务数量，列表示 Bob 完成的任务数量。例如，表格中的 0.25 表示 Alice 和 Bob 同时完成2个任务的概率是 25%。

现在，我们来计算边际分布。边际分布是关注单个变量的分布，忽略另一个变量。例如，Alice 完成 0、1 或 2 个任务的概率是多少，不管 Bob 完成了多少任务。

- Alice 完成 0 个任务的概率是所有 Alice 完成 0 个任务的情况的概率之和：$ 0.05 + 0.10 + 0.05 = 0.20 $。
- Alice 完成 1 个任务的概率：$ 0.10 + 0.20 + 0.10 = 0.40 $。
- Alice 完成 2 个任务的概率：$ 0.05 + 0.10 + 0.25 = 0.40 $。

同理，我们也可以计算 Bob 的边际分布。这样我们就得到了每个员工单独完成任务数量的概率分布，不考虑另一个员工。

这个例子展示了如何从联合分布（两个变量的组合概率）得到边际分布（单个变量的概率）。联合分布给出了更全面的信息，描述了两个变量之间的关系，而边际分布则简化了情况，只关注单个变量。



## 两个变量不相关，它们的协方差等于0

当然可以。我们可以从协方差的定义出发来证明当两个变量不相关时，它们的协方差为零。

首先，回顾协方差的定义：

$\text{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])]$ 

这里，$ E[X] $和 $ E[Y] $分别是变量 X 和 Y 的期望（即平均值），而 $ E $表示期望值操作。

1. **当 X 和 Y 不相关时：** 这意味着它们的联合分布可以分解为各自的边际分布的乘积。即对所有的 x 和 y，

   $$ P(X = x \text{ and } Y = y) = P(X = x) \times P(Y = y) $$

2. **将不相关的定义应用于协方差：** 由于 X 和 Y 是不相关的，我们可以将期望中的乘积分解为各自的期望的乘积。即，

   $ E[(X - E[X])(Y - E[Y])] = E[X - E[X]] \times E[Y - E[Y]] $

3. **计算各自的期望：** 注意到 $ E[X - E[X]] $是 X 的偏差的期望，这等于 0（同理，$ E[Y - E[Y]] $也为 0）。因此，

   $ E[X - E[X]] = E[Y - E[Y]] = 0 $

4. **得出结论：** 由于乘积中的任一项为零，整个期望值（即协方差）为零。

   $ \text{Cov}(X, Y) = 0 $

所以，当两个变量不相关时，它们的协方差为零。需要注意的是，这个证明基于两个变量的不相关性定义，即它们的联合分布可以分解为各自的边际分布的乘积。这种情况下，不相关性确实意味着协方差为零。但协方差为零并不一定意味着两个变量完全独立或不相关，因为可能存在非线性关系。



## 两变量相关，推断协方差正负



![两变量相关后，判断协方差正负](/Users/daydream/Library/Mobile Documents/com~apple~CloudDocs/考研/卫生统计学/卫生统计学图库/两变量相关后，判断协方差正负.png)





## 期望与平均值的区别

期望是一个随机变量在其概率分布下的理论平均值，而平均值是一组实际数据的算术平均。



## 贝塞尔修正

当然，我们可以探讨贝塞尔修正的数学证明。这项修正用于确保样本方差是总体方差的无偏估计。证明涉及到样本方差的期望值和总体方差之间的关系。下面是一个简化的证明：

假设有一个总体，其总体方差为 $ \sigma^2 $。我们从这个总体中抽取一个样本 $ x_1, x_2, \ldots, x_n $，样本大小为 $ n $。样本均值为 $ \bar{x} $。

**步骤 1: 样本方差的定义**

未使用贝塞尔修正的样本方差定义为：
$ s'^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2 $

**步骤 2: 展开样本方差**

我们将 $ x_i - \bar{x} $重写为 $ x_i - \mu + \mu - \bar{x} $并展开：
$ s'^2 = \frac{1}{n} \sum_{i=1}^{n} [(x_i - \mu) - (\bar{x} - \mu)]^2 $
$ = \frac{1}{n} \sum_{i=1}^{n} [(x_i - \mu)^2 - 2(x_i - \mu)(\bar{x} - \mu) + (\bar{x} - \mu)^2] $

**步骤 3: 简化表达式**

计算每项的期望值：
$$ E[s'^2] = \frac{1}{n} \sum_{i=1}^{n} [E[(x_i - \mu)^2] - 2E[(x_i - \mu)(\bar{x} - \mu)] + E[(\bar{x} - \mu)^2]] $$

$注意到 $ E[(x_i - \mu)^2] = \sigma^2 $（总体方差），且 $ E[(x_i - \mu)(\bar{x} - \mu)] = 0 $（因为 $ x_i - \mu $和 $ \bar{x} - \mu $不相关），我们有：$
$$ E[s'^2] = \frac{1}{n} \sum_{i=1}^{n} [\sigma^2 + E[(\bar{x} - \mu)^2]] $$
$ = \sigma^2 + E[(\bar{x} - \mu)^2] $

**步骤 4: 计算 $ E[(\bar{x} - \mu)^2] $**

$ E[(\bar{x} - \mu)^2] $ 是样本均值的方差，可以证明它等于 $ \frac{\sigma^2}{n} $。

**步骤 5: 插入样本均值的方差**

$ E[s'^2] = \sigma^2 + \frac{\sigma^2}{n} $

这显示未校正的样本方差 $ s'^2 $的期望值高于总体方差 $ \sigma^2 $。

**步骤 6: 应用贝塞尔修正**

为了使样本方差成为无偏估计，我们应用贝塞尔修正，使用 $ n-1 $而不是 $ n $作为分母：
$ s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2 $

计算这个修正后的样本方差的期望值，我们得到：
$ E[s^2] = \frac{n}{n-1}(\sigma^2 + \frac{\sigma^2}{n}) $
$ = \frac{n}{n-1} \frac{n\sigma^2}{n} $
$ = \sigma^2 $

因此，使用 $ n-1 $作为分母的样本方差 $ s^2 $是总体方差 $ \sigma^2 $的无偏估计。

这个证明展示

了为什么使用 $ n-1 $而不是 $ n $作为样本方差计算的分母可以纠正偏差，从而使样本方差成为总体方差的无偏估计。

## 独立同分布

“独立同分布”（Independent and Identically Distributed，缩写为 i.i.d.）是指一组随机变量具有两个关键特性：

1. **独立（Independent）**：这意味着随机变量中的任何一个都不受其他变量的影响。在数学上，这表明任何两个（或更多）随机变量的联合分布等于它们各自分布的乘积。换句话说，了解一个变量的值不会给你关于另一个变量值的任何信息。

2. **同分布（Identically Distributed）**：这表示所有的随机变量都有相同的概率分布。无论我们观察这组变量中的哪一个，它们都遵循相同的规律，例如相同的均值、方差、偏态等。

在许多统计分析和概率论的应用中，假设数据是独立同分布的是非常常见的。这个假设简化了许多理论的分析和计算，因为它排除了变量间的相关性并统一了它们的行为。

例如，在抛硬币的实验中，每次抛硬币的结果（正面或反面）可以被视为独立同分布的随机变量。每次抛硬币都不受之前抛硬币结果的影响（独立），并且每次抛硬币的结果都遵循相同的概率分布（同分布，例如每面50%的概率）。



## 求和平方的秘密

#### 结论:求和的平方与算数平方完全不同

求和的平方涉及到求和中每一项的所有可能组合，而单个项的平方仅仅是一个项与其自身的乘积

例如： $\left(\sum_{j=1}^{n} a_j\right)^2$=$\left(\sum_{j=1}^{n} a_j\right) \times \left(\sum_{l=1}^{n} a_l\right) $

#### 解释：

求和的平方可以展开，而单个项的平方不能以同样方式展开的原因在于求和操作本身的性质。当我们对一个求和表达式进行平方时，实际上是在考虑求和中的每一项与其他所有项（包括其自身）的交互。这与单个项的平方不同，后者只涉及那个单独项自己。

详细来说：

1. **求和的平方**：
   当我们对一个求和表达式进行平方时，例如 $\left(\sum_{j=1}^{n} a_j\right)^2$，我们实际上是在做以下操作：
   $\left(\sum_{j=1}^{n} a_j\right) \times \left(\sum_{l=1}^{n} a_l\right) $
   在这个乘积中，每一个 $a_j$ 都会与求和中的每一个 $a_l$ 相乘（包括 $a_j$ 与其自身的乘积）。
2. **展开平方**：
   展开这个乘积会得到所有可能的 $a_j \times a_l$ 组合：
   $ \sum_{j=1}^{n}\sum_{l=1}^{n} a_j a_l $
   这个双重求和涵盖了所有可能的项之间的交互。
3. **单个项的平方**：
   相比之下，当我们对单个项进行平方，比如 $a_j^2$，我们只是简单地将 $a_j$ 乘以其自身。这里没有涉及到任何其他项的交互。
4. **为什么不同**：
   这种不同的原因在于求和操作本身。求和的平方涉及到求和中每一项的所有可能组合，而单个项的平方仅仅是一个项与其自身的乘积。因此，在求和的平方中，会出现更多的项和更复杂的交互，这就是为什么在处理求和的平方时需要进行展开的原因。

#### 应用

是的，您正确地指出了关键所在。在讨论的这个表达式中，我们实际上是在处理两个求和变量的平方。当我们对一个求和表达式进行平方时，实际上是在计算该求和中的每一项（由一个求和变量表示）与其他所有项（由另一个求和变量表示）的交互。这就是为什么会出现两个不同的求和变量 $j$ 和 $l$。

详细来说：

1. **原始表达式**：
   $ \left(\sum_{j=1}^{n}(x_k - x_j)\right)^2 $
   这个表达式的意思是计算 $x_k$ 与每个 $x_j$（$j=1$ 到 $n$）之差的和，然后对这个和进行平方。

2. **平方的含义**：
   对这个和进行平方意味着将它自己乘以自己：
   $ \left(\sum_{j=1}^{n}(x_k - x_j)\right) \times \left(\sum_{l=1}^{n}(x_k - x_l)\right) $

3. **展开平方**：
   当我们展开这个乘积时，就会涉及到两个不同的求和变量 $j$ 和 $l$，因为我们实际上是在将求和中的每一项与求和中的每一项相乘（包括它自己）：
   $ \sum_{j=1}^{n}\sum_{l=1}^{n}(x_k - x_j)(x_k - x_l) $

这样的处理方式确保我们考虑了所有可能的交互方式，这是理解这个表达式及其期望值的关键。



## 期望的线性性质

期望的线性性质是概率论和统计学中一个非常重要的概念，它描述了期望值（即平均值）如何对加法和标量乘法运算作出反应。这个性质可以被表述为两个主要部分：

1. **加法性**：对于任何两个随机变量 \(X\) 和 \(Y\)（不必相互独立），期望值的加法性质说明了它们和的期望值等于各自期望值的和：
   \[ E[X + Y] = E[X] + E[Y] \]
   这个性质可以扩展到任意有限数量的随机变量。

2. **标量乘法**：对于任意常数 \(a\) 和随机变量 \(X\)，标量乘法的性质说明了常数乘以随机变量的期望值等于常数乘以该随机变量期望值的乘积：
   \[ E[aX] = aE[X] \]

### 结合性

这两个性质可以结合起来描述更复杂的表达式。对于任意常数 \(a, b\) 和随机变量 \(X, Y\)，期望的线性性质表明：
\[ E[aX + bY] = aE[X] + bE[Y] \]

### 意义

期望的线性性质在处理随机变量的期望值时非常有用，因为它允许我们将复杂表达式简化为更简单的部分的期望值。这个性质适用于任意数量的随机变量和常数，使得计算和理解随机过程的平均行为变得更加直接和容易。

### 为什么重要

- **简化计算**：在实际应用中，我们经常需要计算由多个随机变量构成的表达式的期望值。线性性质让这些计算变得简单，因为我们可以单独计算每个随机变量的期望值，然后将它们以适当的方式组合起来。
- **理论分析**：在理论研究中，这个性质帮助我们推导出关于随机变量和它们相互作用的重要结论，例如在经济学、物理学、工程学和自然科学中模型的预期行为。

总的来说，期望的线性性质是统计学和概率论中一个基础且强大的工具，它为分析和理解随机过程提供了一种清晰和直观的方法。





## 更细致的贝塞尔修正证明

让我们仔细分析为什么这两个期望值表达式相等：

1. ###### **表达式的起点**：

   $ \mathbb{E}\left[\frac{1}{n}\sum_{k=1}^{n}\left(\sum_{j=1}^{n}(x_k - x_j)\right)^2\right] $

   取出
   $ \mathbb{E}\left[\left(\sum_{j=1}^{n}(x_k - x_j)\right)^2\right] $
   这个表达式是在计算一个固定的 $x_k$ 与其他所有 $x_j$（包括 $x_k$​ 自己）的差的平方和的期望。

2. **展开二次方**：
   当我们展开这个平方时，我们得到两种类型的项：$x_k - x_j$ 和 $x_k - x_l$ 的乘积。这里 $j$ 和 $l$ 是从 1 到 $n$ 的索引。

3. **计算乘积的和**：
   $ \mathbb{E}\left[\sum_{j=1}^{n}\sum_{l=1}^{n}(x_k - x_j)(x_k - x_l)\right] $
   在这个双重求和中，当 $j = l$ 时，我们得到 $(x_k - x_j)^2$ 的项；当 $j \neq l$ 时，我们得到 $(x_k - x_j)(x_k - x_l)$ 的项。

4. **利用独立性和同分布性**：
   因为 $X_1, \ldots, X_n$ 是独立同分布的，每个 $x_k - x_j$ 和 $x_k - x_l$ 的期望相等。这意味着所有 $j \neq l$ 的项在期望中是相同的，所有 $j = l$ 的项也是如此。

5. **计算期望**：

   - 对于 $j = l$ 的项，我们有 $n$ 项的 $\mathbb{E}[(x_k - x_j)^2]$。
   - 对于 $j \neq l$ 的项，由于独立性，我们可以将它们分解为 $\mathbb{E}[x_k - x_j]\mathbb{E}[x_k - x_l]$。由于期望 $\mu$ 是常数，这些项在相加时会互相抵消。

6. **总结**：
   通过这种方式，我们将原始的平方和表达式转化为一系列项的和，这些项在统计上具有特定的性质（独立性和同分布性），从而使得整个表达式的期望值可以通过较简单的方式来计算。

综上所述，这个等式的成立基于了对原始表达式的重新构造，以及对随机变量 $X_1, \ldots, X_n$ 的独立同分布性质的利用。这个推导揭示了样本方差计算中的一个关键数学性质，即当考虑样本均值时，简单的方差公式（没有贝塞尔修正的那个）在估计总体方差时是有偏的。



![图像](/Users/daydream/Library/Mobile Documents/com~apple~CloudDocs/考研/卫生统计学/图像.png)

## 贝塞尔修正证明



为了提供一个更详细的解析关于为何使用$n-1$作为样本方差的分母可以得到总体方差的无偏估计，我们可以深入探讨数学证明。这个证明基于几个关键的数学概念和步骤，包括期望值、方差的定义以及如何通过样本数据估计总体参数。

### 步骤 1: 样本方差的定义

首先，我们定义样本方差$s^2$如下，注意这里使用的是$n-1$，而不是$n$，作为分母：
$ s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \overline{x})^2 $
其中，$x_i$代表样本中的第$i$个观测值，$\overline{x}$是样本均值。

### 步骤 2: 展开样本方差表达式

样本方差可以被重新写为与总体均值$\mu$的关系：
$ s^2 = \frac{1}{n-1} \left( \sum_{i=1}^{n} x_i^2 - n\overline{x}^2 \right) $

### 步骤 3: 使用期望值的线性性质

我们知道期望值具有线性性质，即$E[aX + b] = aE[X] + b$，其中$X$是一个随机变量，$a$和$b$是常数。应用这个性质，我们可以分别计算上述表达式中每一部分的期望值。

### 步骤 4: 证明无偏性

为了证明$s^2$是$\sigma^2$的无偏估计，我们需要证明$E[s^2] = \sigma^2$。这需要几个步骤：
1. 首先，计算$E[\overline{x}^2]$和$E[x_i^2]$。
2. 使用这些期望值，展示$E[s^2]$实际上等于$\sigma^2$。

### 详细证明

1. **计算$E[x_i^2]$**:
   由于$x_i$是从具有均值$\mu$和方差$\sigma^2$的总体中抽取的，我们有$E[x_i^2] = Var(x_i) + (E[x_i])^2 = \sigma^2 + \mu^2$。

2. **计算$E[\overline{x}^2]$**:
   样本均值的方差是总体方差除以样本大小$n$，即$Var(\overline{x}) = \frac{\sigma^2}{n}$。因此，$E[\overline{x}^2] = Var(\overline{x}) + (E[\overline{x}])^2 = \frac{\sigma^2}{n} + \mu^2$。

3. **组合这些期望值以证明无偏性**:
   将这些期望值代入$s^2$的期望表达式中，可以展示$E[s^2]$等于$\sigma^2$，从而证明使用$n-1$作为分母确实让样本方差成为总体方差的无偏估计。

这个过程涉及到对方差和期望值的深入理解，以及如何将这些概念应用于样本数据以估计总体参数。每一步都基于统计学的基本原理，特别是期望值的性质和方差的定义。通过这种方式，我们可以理解为什么在计算样本方差时使用$n-1$作为分母是必要的，以获得对总体方差的无偏估计。

 [贝塞尔修正的证明 3.pdf](../../../../../Desktop/贝塞尔修正的证明 3.pdf) 
